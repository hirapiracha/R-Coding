---
author: "Marc Kaufmann"
title: "Lecture 5"
date: "02/05/2024"
output: 
  html: default
  pdf: default
---

## summarise()

```{r libraries}
#| output: false
library(tidyverse)
library(nycflights13)
```

```{r useless-summary}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

How... useful. Might as well have done:

```{r mean-directly}
mean(flights$dep_delay, na.rm = TRUE)
```

Reminder: `<data-frame>$<column-name>` returns the column `<column-name>` from 
`<data-frame>`, which is a quick way to select a column.

Note that this is different from using `select` on a column:
```{r try}
mean(select(flights, dep_delay), na.rm = TRUE)
```

Huh? What's going on here? 

```{r select-vs-dollar}
#| output: FALSE
flights$dep_delay
select(flights, dep_delay)
```

Aha, we should have guessed, since select returns a *data frame*,
but `mean` expects a vector. A data frame of 1 column is not the same as 
a vector column.

So, what else can we use `summarise` for? To make it useful, we neeed its friend,
`group_by`:

```{r group-by}
by_day <- group_by(flights, year, month, day)
by_day
```

Looks distinctly the same. But it really isn't!

```{r useful-command}
summarise(
  group_by(flights, year, month, day), 
  delay = mean(dep_delay, na.rm = TRUE)
)

# Or, using the pipe
flights |>
  group_by(year, month, day) |>
  summarise(
    delay = mean(dep_delay, na.rm = TRUE)
  )
```

## 5.6.1 of R4DS

Let's explore link between distance and average delay for every location. What that means is that we want to know the average delay for every destination. Then, once we have that, we want to see how the distance to this location is related to the delay to this location.

```{r dist-delay-by-location}
by_destination <- group_by(flights, dest)
flights_delay <- summarise(
  by_destination,
  avg_arr_delay = mean(arr_delay, na.rm = TRUE)
)
flights_delay
```

OK, we need the distance too, or else there is not much to plot.

```{r dist-delay-by-location2}
(flights_delay <- summarise(
  by_destination,
  avg_arr_delay = mean(arr_delay, na.rm = TRUE),
  distance = mean(distance, na.rm = TRUE) # Somewhat of a hack
))

p <- ggplot(data = flights_delay,
            mapping = aes(x = distance, y = avg_arr_delay))
p + geom_point() + geom_smooth()

(flights_delay <- summarise(by_destination,
                    count = n(), 
                    avg_arr_delay = mean(arr_delay, na.rm = TRUE),
                    distance = mean(distance, na.rm = TRUE)))

p <- ggplot(data = flights_delay,
            mapping = aes(x = distance, y = avg_arr_delay))
p + geom_point(mapping = aes(size = count), alpha = 0.2) +
  geom_smooth()
```

We used the function `n`, which is special and works only inside of `summarize`:

```{r n}
#| eval: FALSE
n()
```

**Optional Exercise (harder):** The above smoothing does not take into account the number of flights per location - we only plot points by weight. A location with 1 flight matters as much for smoothing as a location with 300. 

That is rarely what we want when smoothing globally. Read the following code, to see if you understand how it works. 

Let's plot the original data, without first taking means by group

```{r opt-exercise}
#| message: FALSE
#| warning: FALSE

# Woah, that looks different! (And ugly.)
p2 <- ggplot(data = flights,
             mapping = aes(x = distance, y = arr_delay))
p2 + geom_point(alpha = 0.2) + geom_smooth()

# Now let's plot points by location as before, but run geom_smooth on whole dataset
p2 + geom_point(data = flights_delay, aes(y = avg_arr_delay, size = count), alpha = 0.3) +
  geom_smooth()
# So, not too misleading, but still...
```

Doing this with a pipe, and filtering out destinations with 
- less than 20 flights
- to HNL (Honululu), since it's by far the furthest

Note: I am not a big fan of dropping things that 'look too different'. You should do such robustness checks, but you shouldn't start there. 

```{r hnl}
delays <- flights %>% 
  group_by(dest) %>%
  summarise(
    avg_arr_delay = mean(arr_delay, na.rm = TRUE),
    count = n(),
    distance = mean(distance, na.rm = TRUE)
    ) %>%
  filter( count > 20, dest != "HNL")
```

**Exercise:** Rewrite the above command without the pipe. Which one do you find easier to read?

## 5.6.2 Missing values

```{r missing-values}
not_missing <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
```

**Exercise:** Does the above command also drop observations that miss only the arr_delay but have a dep_delay? Are there any observations in the dataset for which only dep_delay or arr_delay is missing, but not both?

## 5.6.3 Counts

Average delay by airplane (identified by tailnum), plot density.
Start with freqpoly, then zoom in on that part of the graph that we are interested:

```{r counts}
library(ggplot2)
not_missing %>%
  group_by(tailnum) %>%
  summarise(avg_delay = mean(dep_delay)) %>%
  ggplot(mapping = aes(x = avg_delay)) + 
  geom_histogram(binwidth = 10)
```

Plot the number of flights per airplane against delay:

```{r flights-against-delays}
not_missing %>%
  group_by(tailnum) %>%
  summarise(
    count = n(),
    avg_delay = mean(arr_delay)
    ) %>%
  ggplot(mapping = aes(x = avg_delay, y = count)) + 
  geom_point(alpha = 0.1)
```
         
Since I am filtering the same thing all the time, let's store it in a variable and drop the rest:

```{r store-filtered}
not_missing_planes <- not_missing |>
  group_by(tailnum) |>
  summarise(
    count = n(),
    avg_delay = mean(arr_delay),
    delay_median = median(arr_delay)
    )
```

Get the median delay for each airplane:

```{r median-delay}
ggplot(data = not_missing_planes) + 
  geom_histogram(mapping = aes(x = delay_median)) + 
  geom_histogram(mapping = aes(x = avg_delay), color = 'yellow', alpha = 0.3)
```

Filter the airplanes that fly rarely and pipe them into ggplot which gets plussed into geoms. Try a few values for how many flights one should have done

```{r final}
#| message: FALSE
not_missing_planes %>%
  filter(count > 5) %>%
  ggplot(mapping = aes(x = avg_delay)) + 
  geom_histogram()
```

## 5.6.4 Summary Functions

You should be aware of the following functions that you can use with `summarise()` should you need them:

```{r}
x <- 1:100
median(x)
sd(x)
IQR(x)
mad(x)
?mad
min(x)
max(x)
```

An important difference between the mean and the median is that the median is more robust to outliers. Often when people say 'the average person', they have in mind the 'median person', not the average person. 

```{r}
# Example
x <- 1:100
mean(x)
median(x)
x_with_outlier <- c(x, 1000000000)
mean(x_with_outlier)
median(x_with_outlier)
```

Sometimes you want the mean, not the median, but you have to be aware of what it tells you.

### Quantile

An important one is `quantile()`:

```{r}
# What does quantile do?
?quantile

# Not that helpful. Here's what I do when I am not sure
x <- 1:100
quantile(x, 0.25)
quantile(x, 0.20)
quantile(x, 0.50)
y <- 1:5
quantile(y, 0.50)
z <- c(0,0,0,0,0,1,2,100,100)
quantile(z, 0.90)
quantile(z, 0.50)
quantile(z, 0.40)
```

### Counts

You'll often want to count things.

```{r}
# Count the number of flights to each destination
library(nycflights13)
library(tidyverse)

not_missing <- flights %>%
  filter(!is.na(arr_time), !is.na(dep_time)) %>%
  filter(!is.na(arr_delay), !is.na(dep_delay))

not_missing %>%
  group_by(dest) %>%
  summarise(
    count = n()
  )

# Count the number of distinct carriers to each location
not_missing %>%
  group_by(dest) %>%
  summarise(
    carriers = n_distinct(carrier)
  ) %>%
  arrange(desc(carriers))
```

Since they are so important and common, there is a shorthand for `group_by(...) %>% summarise(count = n())` called `count(...)`:

```{r}
# Short hand
not_missing %>%
  count(dest)
```

This is good enough for simple counts, but you may want to weight the counting, or get sums, or get averages:

```{r}
# This counts how many airmiles a given airplane did from NYC
not_missing %>%
  count(tailnum, wt = distance)

not_missing %>%
  count(tailnum, wt = distance) %>%
  arrange(desc(n))

## Number of flights each day before 5am
not_missing %>%
  group_by(year, month, day) %>%
  summarise(sum(dep_time < 500))

# What proportion of flights is delayed each day by more than 1 hour?
not_missing %>%
  group_by(year, month, day) %>%
  summarise(one_hour_fc = mean(arr_delay > 60))

# Class Exercise: Why do I use the mean above? How does that get the proportion?
```

### Ungrouping

If you want to get rid of earlier groupings, use `ungroup()`:

```{r}
daily <- flights %>%
  group_by(year, month, day)

daily2 <- flights %>%
  group_by(year, month, day)

daily %>%
  ungroup() %>%
  summarise(n())
```

**Question:** Given the answer, what is the default grouping and how many groups are there?

## Exercises for Lecture 5 (Optional)

**Exercise 1:** Using the nycflights13 data. Note that it also contains a tibble called `airports` (as well as others). Use these two dataframes to find the answer to 5 of the following, and print them out in a separate chunk (i.e. the chunk should print the tibble, thus showing the first 10 lines of each):

- The number of flights (in the whole year) to each destination
- The number and list of distinct airports in the US
- The number and list of distinct airports that have at least one flight in the whole year from NYC
- The number and list of distinct airports that have at least one flight **per day (on average)** from NYC
- The number airports that are further south than NYC (Hint: look up longitude and latitude.)
- The top 5 carriers that have the lowest average delay times. 
- What is the worst day of the year to fly in terms of arrival delay?
- What is the best day of the year to fly in terms of departure delay?

Reminder: Pick only 5 of the 8 possible ones.

**Exercise 2:** Find all the rows with no NA values in **the first two columns** for the following datasets: 

- diamonds
- flights
- mtcars

Now find the subsets of data that contain no NA values. You don't want to do that in the same way. Can you figure out how to use `across()` to do the job? You may have to read some documentation to figure it out.

If you can't find a dataset, do `??<dataset>` to find out more about it and what library you need to load. 

**Exercise 3:** You can also use `across()` to check for those lines where *any* value is NA -- that is, keep only rows where some value is NA, no matter which column. You can also use `filter_all` and look at the examples at the end of the documentation. Look in the documentation of `across()` for `filter_all` to see how you can use `across()`. If you can't figure it out, at least point out the code. Use this (with some google-fu or discourse help) to find all the rows with NA values in *any* column for the following datasets: 

- diamonds
- flights
- mtcars

Thus, the output should be those rows that *do* contain NA values. 

**Exercise 4:** Pick your favourite dataset. Use it to illustrate the following types of plots, and describe briefly (2-3 sentences) what each plot means. I.e. for the boxplot, what do different lines mean in general, and thus what do they say about the specific data, such as the mean?

- boxplot
- violin plot
- boxploth (Hint: You need to import the right library for this)
- bin2d
- hex

Thus the code for each plot should be `ggplot(data = <your-data-set>, mapping = aes(...) + geom_...()` and is not the main challenge. The main part is for you to look at and understand the data.

**Exercise 5:** Come up with an exercise to help you  -- and others -- learn `summarise` and `group_by` better. The more confused you are, the more you should simply try to come up with, or even copy, an example from somewhere and highlight what confuses you. Is it the order or arguments? Their role? If you are less confused, try to find a (non-obvious) use. Mention any resources used. 

**Exercise 6:** Work through sections 11.1 and 11.2 (skip exercises).