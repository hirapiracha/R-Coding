---
title: "Instructions for Toy Data Report"
author: "Marc Kaufmann"
format: html
editor: visual
---

# Introduction

These instructions guide you through the process of writing your first toy (ungraded) data report. The goal is to familiarize you with the structure I expect from your later data reports.

We will cover the following steps:

-   Where to get help if you are stuck
-   Creating the Quarto document
-   Creating all the sections:
    -   Dataset Description (15 points)
    -   Cleaning (20 points)
    -   Exploration (30 points)
    -   Conclusion (15 points)
    -   Code Exercise and Explanation (20 points)
-   Describe contents of each section
-   Conventions to follow

Make sure to render your document after every step (or more often) to check for errors.

# Getting Help

Before starting, you may want to watch the first 10 minutes of the [Get Started](https://quarto.org/docs/get-started/hello/rstudio.html) video at the Quarto wepsite. The website provides further documentation and resources on Quarto if you are interested to peek around, and you should search for answers to your problems there, on google, on Slack, or with ChatGPT (my guess is it won't be great, since there is not yet a lot of Quarto code, but I may be wrong).

When posting on Slack, include what you tried and why that didn't work as you expected. If you didn't try anything, include what you searched for. Others will be more likely to help you if they feel you put in the time yourself.

# Create Quarto Document

In RStudio, go to File -\> New File -\> Quarto Document, provide title and author information, and choose HTML format as output. There will already be some text by default, you can remove or edit it as appropriate.

# Create Sections

Each data report requires exactly the same top level sections. To add a new section, insert a new heading. You can do so in three ways:

1.  In the *Source* editor, you can type `# HEADER`
2.  In the *Visual* editor, you can click on a new line and choose the *Header 1* as font size (look at the bar next starting with the choice of *Source* and *Visual* )
3.  In the *Visual* editor, you can click on a new line, type `/` which starts a search functionality. Typing `h` will get you the list of headers (among others), which you can select.

Play around with the methods to see which you like best. Insert all the headers mentioned in the introduction, calling them exactly the same as I did above.

# Section Descriptions

We start with the **Dataset Description.**

## Dataset Description

For this toy report, you will use the following dataset collected in our first lecture:

```{r toy-data}
list_of_programming_languages <- c(
  "R",
  "SQL",
  "Racket",
  "Lisp",
  "JavaScript",
  "ECMAScript",
  "Julia",
  "bash",
  "C",
  "Perl",
  "Logo",
  "Scratch", 
  "Rust",
  "Python"
)

languages_heard_of <- c(20, 19, 0, 0, 19, 1, 3, 4, 16, 1, 1, 5, 1, 1)
```

Copy this code into a code block in R. Similar to headers, there are several ways of adding code blocks, worst case by typing the characters "`{r}`" in the *Source* editor. Figure it our on your own and ask in Slack if you are stuck.

Given the absolute simplicity of our data, there is not much to describe, but briefly describe it as if to a person who might read this in a year or two and not know about the context where the data came from. Things to include:

-   The source of the raw data: who collected it, when, on what population?

-   What data is there: how many files, what is their format, which variables are in which file, what do they mean, how was the variable established (e.g. measured in person, self-report, etc)...

-   Any potential issues: was there some data imputation due to data corruption, what do some of the special codes mean, what information is missing

It is your judgement whether you want to include some subset of the data to illustrate and highlight some issues or not.

## Cleaning

In this section, you write the code that generates the clean data from the raw data. That is, you get it into a shape where it is easier for you to analyse; you change the names to more meaningful ones or ones that are easier to type for analysis; you may already decide to drop some data or impute some data or replace it by `NA` depending on some clear issues. You also may reshape the data by making it 'tidy' which makes it easier to analyse or store more efficiently (we will see what this means later). You should then store the cleaned data in one or more files, again documenting which variables are where.

Each step should be done automatically by your code and be run upon rendering, and you should comment each step, either by a comment in the code for simple steps (e.g. `# Replace "." by "NA"`), while more elaborate steps should be describe in the main body of the text.

When dropping some data or changing some values, you have to provide some evidence why this is justified, whether by providing a table or a graph, or (for specific values), just state that they took specific values.

For this toy report, our dataset is so simple there are only a few things to do:

1.  Stata is misspelled as \$tata (truly hilarious), which you should rename. Look at the
2.  The data is currently stored in two separate vectors. It is better to store it instead in a single data frame with one column for the programming language and one for the number of students who have heard of it.
3.  We should record the total number of students present - which seems like an important quantity not included in the original data. Pick a descriptive name.

For this report, you don't need to store the toy data to a file.

Since we haven't seen how to change values of a vector or set the value of a data frame, here is some code that you can change to achieve the goal (you have to apply it to other variables, obviously):

```{r set-value}
v <- c("bla", "bladibla")

# You can get the first element of the vector by writing v[1], the nth by writing v[n]
v[1] # -> "bla"
v[2] # -> "bladibla"

# Let's change the value of "bla" to "unknown"
v[1] <- "unknown"

# Check it worked
v[1]
```

As for creating a data frame from two vectors of the same length, you can do the following (see `?data.frame` for more information):

```{r dataframe-from-vectors}
v1 <- c(0, 1, 2)
v2 <- c("a", "c", "b")

# Create dataframe with one column called `number` and one called `letter`
df <- data.frame(number = v1, letter = v2)

# Look at the data
df
```

The vectors have to be of the same length (or one has to be a multiple of the other - see documentation), since you give data.frame the name of each column, and each column has to have the same length.

## Exploration

Now it is up to you to answer some interesting question, either one given by me or (if left open) of your own choosing. This section should be the most extensive, include at some summary statistic or table (or multiple) and at least one plot or visualization of some kind.

For our toy data, rank the languages from most to least well-known and compute the average number of students who know any language, as well as the average number of languages a student knows.

For the ranking, use the `arrange` function from the `dplyr` package, which we will see in more detail in a later lecture. It arranges a dataframe in the order of the column provided. An example:

```{r arrange-example}
library(dplyr)

# This assumes you ran the chunk above that defined `df`
arrange(df, desc(letter))
arrange(df, letter)
```

Note that you choose the column by which you order or 'arrange' the rows, and this reorders whole rows, not just that column (each row is one observation, so that wouldn't make sense). You can choose the direction of ordering with `desc(...)` which orders in a descending fashion, by default it is ascending.

Finally, find a plot with which to visualize the fraction of students that knows each language.

## Conclusions

What it says on the tin.

For the toy data, fill in the following template:

"The most well-known programming language is ... with ... students knowing the language â€” in percentage terms, this corresponds to ...%.

Moreover, students know on average ... of the ... languages they were asked about.

Follow-up questions:

...".

## Code Exercise and Explanation

In each data report, there will be some coding section in which you provide the code to answer some exercise(s), and some explanation of code in your analysis.

**Exercise 1:** From the `starwars` dataset (in `tidyverse`), keep all the rows with characters that are non-human and with eye color that is 'yellow', 'blue-gray', or contains either of those.

**Code Explanation:** Explain your plot in the previous part (briefly), i.e. each major command does, and any important arguments that you change. You do not have to say that "`data = df` means that I am using `df` as the `data`", but you should mention what a given `geom_*` is doing and how to read or interpret it. Again, a histogram doesn't require much explanation, a violin plot does require a bit more.

# Conventions to Follow

I expect the following conventions (among others that I may have mentioned in passing - this list is not exhaustive):

-   Each code chunk should have a label, such as `cleaning` or `store-data`. Labels of code chunks have to be unique.

-   Assignment in R is to be done with the `<-` operator, not `=`. The equal sign `=` is used inside of data frames, to set arguments in function calls, etc.

-   Everything needed to replicate the report needs to be in the .qmd file, plus the original raw data. No manual steps. If you cannot figure out how to automate a step, you can do it manually, highlight it clearly, and do the next steps based on the manual inputs.
